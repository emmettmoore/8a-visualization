<!DOCTYPE html>
<html>
<head>
        <title>Viz Final Project Ideas</title>
        <link rel="stylesheet" type="tex`t/css" href="style.css">
</head>
<body>

# Visualization Final Project Ideas

## [8a.nu][3] Visualization

### Possible Stories
1.	Routes that are popular are soft.
2.  Visualize areas that are soft vs. sandbagged (heatmap)
3.  (Even simpler) visualize traffic to different areas
4.  Visualize who travels to where
5.  Where people from certain areas typically climb.... Unique URL from "city score" page.

### Complications
1.	Complex. Requires determining a valid metric of soft vs. sandbagged, classics vs. non-classics.
    - Notes that the data in this database _only includes ascents_. This means that we have no data on the opinions of those that may have gotten pummeled on a route. 
    - This means that there is probably no easy way to detect that sandbags are not "classic".
2.  8a combines unreliable user data with poor organization.
    -   Users log routes, and 8a adds a new climb to the database if there is not "collision".
    -   The site doesn't give a useful link (it is "8a.nu") for each page until reached individual climbs, or user pages.
        - This is a problem for Scrapy.. see below
    -   If a climb is logged with two different grades in the database, we will see it twice in the "area" list. Both links will go to the same place, however.
    -   This allows for users to accidentally spell climbs wrong and have them added to the DB wrong.
    -   Anonymous accounts must be filtered out (don't go to an actual logbook; just says "this user is anonymous").


### We Need to Make a Crawler
- [SO How to Write a Crawler][1]
- Frames, wtf. If a URL (not 8a.nu) is searched, it uses the URL as a field in html/body/form called "action". Action loads the new data, and changes the data in the tables.
    - We might have to take [special considerations][7], or just focus on one (or a few) climbing areas, using <code>curl</code> to grab the inital tables.
        - If we were to use <code>curl</code> then we would only be able to get the data in the links in the main table (i.e. the climb's info, and who sent it) if the data on those links were not "generated" by similar means to the data on the climbing area's main table.
        - Of course, this is not the case so we need to figure out a way to generate the tables programmatically.
- Say we hard-code the starting places to get this data. We will start at an areas list of classics (e.g. the [RRG][4]),
- [SO Scraping a Table with Scrapy][6]
- [Scrape Links from Table with Scrapy][8]

#### Crawler Pseudocode<pre><code>    
    for area in areas: # This won't *yet* be done programatically. 
                       # Too difficult, since we don't have RESTful URLs for these sites.
        for line in climbs_list:
            climbs.append(climb(line['url'])) # take in the url as a constructor arg. Constructor does the rest.
                                              # Once you get to a climb's link, the url is relocatable 
                                              # (i.e. not 8a.nu. Of course it is really long and ugly instead).
</pre></code>

### Scraping Libraries
-   [Scrapy][5]
</body>
</html>
[1]: http://www.example.com/ "Example"
[2]: http://stackoverflow.com/questions/102631/how-to-write-a-crawler "Crawler"
[3]: http://www.8a.nu/ "8a.nu"
[4]: http://www.8a.nu/Scorecard/Search.aspx?HideSearchForm=1&Mode=SIMPLE&CragCountryCode=USA&AscentType=0&CragName=Red+River+Gorge "RRG"
[5]: http://scrapy.org/ "Scrapy"
[6]: http://stackoverflow.com/questions/17431887/table-needs-to-be-scraped-with-scrapy "SO Scrapy Scraping tables"
[7]: http://stackoverflow.com/questions/19433961/scrapy-hxs-select-not-selecting-all-results "Potential Problems with 8a's table generation"
[8]: http://stackoverflow.com/questions/17447784/scrape-links-from-a-table-with-scrapy?rq=1 "Scrape Links from Table with Scrapy"
